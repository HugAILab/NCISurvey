## Paper collection for Langauge Models for Code
### Encoder-Only

1. [ICLR2021] **GraphCodeBERT: Pre-training Code Representations with Data Flow.** [![arXiv](https://img.shields.io/badge/arXiv-2009.08366-b31b1b.svg)](https://arxiv.org/abs/2009.08366), 2020.09
   
  *Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, Ming Zhou* 


2. [EMNLP2020] **CodeBERT: A Pre-Trained Model for Programming and Natural Languages.** [![arXiv](https://img.shields.io/badge/arXiv-2002.08155-b31b1b.svg)](https://arxiv.org/abs/2002.08155), 2020.02
   
  *Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, Ming Zhou* 


3. [ICML2020] **Learning and Evaluating Contextual Embedding of Source Code.** [![arXiv](https://img.shields.io/badge/arXiv-2001.00059-b31b1b.svg)](https://arxiv.org/abs/2001.00059), 2019.12
   
  *Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, Kensen Shi* 


### Decoder-Only
1. [[ESEC/FSE2020]](https://2020.esec-fse.org/details/esecfse-2020-industry-papers/13/IntelliCode-Compose-Code-Generation-using-Transformer) `GPT-C` **IntelliCode Compose: Code Generation using Transformer.** [![arXiv](https://img.shields.io/badge/arXiv-2005.08025-b31b1b.svg)](https://arxiv.org/abs/2005.08025), 2020.05

   *Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, Neel Sundaresan*

2. [[MAPS2022]](https://dl.acm.org/doi/abs/10.1145/3520312.3534862) `PolyCoder` **A Systematic Evaluation of Large Language Models of Code.** [![arXiv](https://img.shields.io/badge/arXiv-2202.13169-b31b1b.svg)](https://arxiv.org/abs/2202.13169), 2022.02

   *Frank F. Xu, Uri Alon, Graham Neubig, Vincent J. Hellendoorn*
   
3. [[ICLR2023]](https://openreview.net/forum?id=iaYcJKpY2B_) **CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis.** [![arXiv](https://img.shields.io/badge/arXiv-2203.13474-b31b1b.svg)](https://arxiv.org/abs/2203.13474), 2022.03

   *Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong*
   
4. [[JMLR]](https://jmlr.org/papers/v24/22-1144.html) `PaLM-Coder` **PaLM: Scaling Language Modeling with Pathways.** [![arXiv](https://img.shields.io/badge/arXiv-2204.02311-b31b1b.svg)](https://arxiv.org/abs/2204.02311), 2022.04

   *Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, Noah Fiedel*

5. [[ICLR2023]](https://openreview.net/forum?id=hQwb-lbM6EL) **InCoder: A Generative Model for Code Infilling and Synthesis.** [![arXiv](https://img.shields.io/badge/arXiv-2204.05999-b31b1b.svg)](https://arxiv.org/abs/2204.05999), 2022.04

   *Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, Ruiqi Zhong, Wen-tau Yih, Luke Zettlemoyer, Mike Lewis*

6. [[IJCAI2022]](https://www.ijcai.org/proceedings/2022/329) `PyCodeGPT` **CERT: Continual Pre-Training on Sketches for Library-Oriented Code Generation** [![arXiv](https://img.shields.io/badge/arXiv-2206.06888-b31b1b.svg)](https://arxiv.org/abs/2206.06888), 2022.06

   *Daoguang Zan, Bei Chen, Dejian Yang, Zeqi Lin, Minsu Kim, Bei Guan, Yongji Wang, Weizhu Chen, Jian-Guang Lou*

7. [Preprint] **PanGu-Coder: Program Synthesis with Function-Level Language Modeling.** [![arXiv](https://img.shields.io/badge/arXiv-2207.11280-b31b1b.svg)](https://arxiv.org/abs/22207.11280), 2022.07

   *Fenia Christopoulou, Gerasimos Lampouras, Milan Gritta, Guchun Zhang, Yinpeng Guo, Zhongqi Li, Qi Zhang, Meng Xiao, Bo Shen, Lin Li, Hao Yu, Li Yan, Pingyi Zhou, Xin Wang, Yuchi Ma, Ignacio Iacobacci, Yasheng Wang, Guangtai Liang, Jiansheng Wei, Xin Jiang, Qianxiang Wang, Qun Liu*

8. [Preprint] `FIM` **Efficient Training of Language Models to Fill in the Middle.** [![arXiv](https://img.shields.io/badge/arXiv-2207.14255-b31b1b.svg)](https://arxiv.org/abs/2207.14255), 2022.07

   *Mohammad Bavarian, Heewoo Jun, Nikolas Tezak, John Schulman, Christine McLeavey, Jerry Tworek, Mark Chen*

9. [Preprint] **SantaCoder: don't reach for the stars!** [![arXiv](https://img.shields.io/badge/arXiv-2301.03988-b31b1b.svg)](https://arxiv.org/abs/2301.03988), 2023.01

   *Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, Manuel Romero, Michael Lappert, Francesco De Toni, Bernardo García del Río, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky, Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes, Daniel Fried, Arjun Guha, Harm de Vries, Leandro von Werra* 
   
10. [[CoRR2023]](https://openreview.net/forum?id=NRhaCyPhQbm) **CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X.** [![arXiv](https://img.shields.io/badge/arXiv-2303.17568-b31b1b.svg)](https://arxiv.org/abs/2303.17568), 2023.03

   *Qinkai Zheng, Xiao Xia, Xu Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang, Lei Shen, Andi Wang, Yang Li, Teng Su, Zhilin Yang, Jie Tang* 
   

11. [[TMLR]](https://openreview.net/forum?id=KoFOg41haE) **StarCoder: may the source be with you!** [![arXiv](https://img.shields.io/badge/arXiv-2305.06161-b31b1b.svg)](https://arxiv.org/abs/2305.06161), 2023.05

   *DRaymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, Harm de Vries*

11. [Preprint] **WizardCoder: Empowering Code Large Language Models with Evol-Instruct.** [![arXiv](https://img.shields.io/badge/arXiv-2306.08568-b31b1b.svg)](https://arxiv.org/abs/2306.08568), 2023.6

   *Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, Daxin Jiang* 

12. [Preprint] **Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models.** [![arXiv](https://img.shields.io/badge/arXiv-2311.09278-b31b1b.svg)](https://arxiv.org/abs/2311.09278), 2023.11

   *Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, Jun Liu* 

   <!-- *Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, Jun Liu*  [[pdf](https://arxiv.org/abs/2311.09278)], 2022.5 -->

### Encoder-Decoder

1. [EMNLP2023] **CodeT5+: Open Code Large Language Models for Code Understanding and Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2305.07922-b31b1b.svg)](https://arxiv.org/abs/2305.07922), 2023.05

   *Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D.Q. Bui, Junnan Li, Steven C.H. Hoi* 

2. [ACL2023] **ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages.** [![arXiv](https://img.shields.io/badge/arXiv-212.06742-b31b1b.svg)](https://arxiv.org/abs/2212.06742), 2022.12

   *Yekun Chai, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu* 

3. [ACL2022] **UniXcoder: Unified Cross-Modal Pre-training for Code Representation.** [![arXiv](https://img.shields.io/badge/arXiv-2203.03850-b31b1b.svg)](https://arxiv.org/abs/2203.03850), 2022.03

   *Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, Jian Yin* 

4. [Science] **Competition-Level Code Generation with AlphaCode.** [![arXiv](https://img.shields.io/badge/arXiv-2203.07814-b31b1b.svg)](https://arxiv.org/abs/2203.07814), 2022.02

   *Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, Oriol Vinyals*

5. [EMNLP2021] **CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2109.00859-b31b1b.svg)](https://arxiv.org/abs/2109.00859), 2021.09

   *Yue Wang, Weishi Wang, Shafiq Joty, Steven C.H. Hoi* 

6. [NAACL2021] **Unified Pre-training for Program Understanding and Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2103.06333-b31b1b.svg)](https://arxiv.org/abs/2103.06333), 2021.03

   *Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang* 


## Others

1. [EMNLP2023] **CodeFusion: A Pre-trained Diffusion Model for Code Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2310.17680-b31b1b.svg)](https://arxiv.org/abs/2310.17680), 2023.10

   *Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, Gust Verbruggen* 
