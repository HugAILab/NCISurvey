## Paper collection for Langauge Models for Code
### Encoder-Only

1. [ICLR2021] **GraphCodeBERT: Pre-training Code Representations with Data Flow.** [![arXiv](https://img.shields.io/badge/arXiv-2009.08366-b31b1b.svg)](https://arxiv.org/abs/2009.08366), 2020.09
   
  *Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, Ming Zhou* 


2. [EMNLP2020] **CodeBERT: A Pre-Trained Model for Programming and Natural Languages.** [![arXiv](https://img.shields.io/badge/arXiv-2002.08155-b31b1b.svg)](https://arxiv.org/abs/2002.08155), 2020.02
   
  *Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, Ming Zhou* 


3. [ICML2020] **Learning and Evaluating Contextual Embedding of Source Code.** [![arXiv](https://img.shields.io/badge/arXiv-2001.00059-b31b1b.svg)](https://arxiv.org/abs/2001.00059), 2019.12
   
  *Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, Kensen Shi* 


### Decoder-Only
1. [[ESEC/FSE2020]](https://2020.esec-fse.org/details/esecfse-2020-industry-papers/13/IntelliCode-Compose-Code-Generation-using-Transformer) `GPT-C` **IntelliCode Compose: Code Generation using Transformer.** [![arXiv](https://img.shields.io/badge/arXiv-2005.08025-b31b1b.svg)](https://arxiv.org/abs/2005.08025), 2020.05

   *Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, Neel Sundaresan*

2. [[MAPS2022]](https://dl.acm.org/doi/abs/10.1145/3520312.3534862) `PolyCoder` **A Systematic Evaluation of Large Language Models of Code.** [![arXiv](https://img.shields.io/badge/arXiv-2202.13169-b31b1b.svg)](https://arxiv.org/abs/2202.13169), 2022.02

   *Frank F. Xu, Uri Alon, Graham Neubig, Vincent J. Hellendoorn*
   
3. [[ICLR2023]](https://openreview.net/forum?id=iaYcJKpY2B_) **CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis.** [![arXiv](https://img.shields.io/badge/arXiv-2203.13474-b31b1b.svg)](https://arxiv.org/abs/2203.13474), 2022.03

   *Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong*
   
4. [[JMLR]](https://jmlr.org/papers/v24/22-1144.html) `PaLM-Coder` **PaLM: Scaling Language Modeling with Pathways.** [![arXiv](https://img.shields.io/badge/arXiv-2204.02311-b31b1b.svg)](https://arxiv.org/abs/2204.02311), 2022.04

   *Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, Noah Fiedel*

5. [Preprint] **Symbol-LLM: Towards Foundational Symbol-centric Interface For Large Language Models.** [![arXiv](https://img.shields.io/badge/arXiv-2311.09278-b31b1b.svg)](https://arxiv.org/abs/2311.09278), 2023.11

   *Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, Jun Liu* 

   <!-- *Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, Jun Liu*  [[pdf](https://arxiv.org/abs/2311.09278)], 2022.5 -->

### Encoder-Decoder

1. [EMNLP2023] **CodeT5+: Open Code Large Language Models for Code Understanding and Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2305.07922-b31b1b.svg)](https://arxiv.org/abs/2305.07922), 2023.05

   *Yue Wang, Hung Le, Akhilesh Deepak Gotmare, Nghi D.Q. Bui, Junnan Li, Steven C.H. Hoi* 

2. [ACL2023] **ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for Programming Languages.** [![arXiv](https://img.shields.io/badge/arXiv-212.06742-b31b1b.svg)](https://arxiv.org/abs/2212.06742), 2022.12

   *Yekun Chai, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu* 

3. [ACL2022] **UniXcoder: Unified Cross-Modal Pre-training for Code Representation.** [![arXiv](https://img.shields.io/badge/arXiv-2203.03850-b31b1b.svg)](https://arxiv.org/abs/2203.03850), 2022.03

   *Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming Zhou, Jian Yin* 

4. [Science] **Competition-Level Code Generation with AlphaCode.** [![arXiv](https://img.shields.io/badge/arXiv-2203.07814-b31b1b.svg)](https://arxiv.org/abs/2203.07814), 2022.02

   *Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, Oriol Vinyals*

5. [EMNLP2021] **CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2109.00859-b31b1b.svg)](https://arxiv.org/abs/2109.00859), 2021.09

   *Yue Wang, Weishi Wang, Shafiq Joty, Steven C.H. Hoi* 

6. [NAACL2021] **Unified Pre-training for Program Understanding and Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2103.06333-b31b1b.svg)](https://arxiv.org/abs/2103.06333), 2021.03

   *Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang* 


## Others

1. [EMNLP2023] **CodeFusion: A Pre-trained Diffusion Model for Code Generation.** [![arXiv](https://img.shields.io/badge/arXiv-2310.17680-b31b1b.svg)](https://arxiv.org/abs/2310.17680), 2023.10

   *Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, Gust Verbruggen* 
